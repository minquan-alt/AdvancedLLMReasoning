{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "116ef68b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such files: '/home/quang_ai/AdvancedLLMReasoning/data_utils/data/subset_openmathinstruct_1/256K/dataset_info.json', nor '/home/quang_ai/AdvancedLLMReasoning/data_utils/data/subset_openmathinstruct_1/256K/state.json' found. Expected to load a `Dataset` object but provided path is not a `Dataset`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 3\u001b[0m subset_ds \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/subset_openmathinstruct_1/256K\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/datasets/arrow_dataset.py:1676\u001b[0m, in \u001b[0;36mDataset.load_from_disk\u001b[0;34m(dataset_path, keep_in_memory, storage_options)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset_dict_is_file:\n\u001b[1;32m   1673\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1674\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such files: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_info_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, nor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_state_json_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found. Expected to load a `Dataset` object, but got a `DatasetDict`. Please use either `datasets.load_from_disk` or `DatasetDict.load_from_disk` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1675\u001b[0m         )\n\u001b[0;32m-> 1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1677\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such files: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_info_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, nor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_state_json_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found. Expected to load a `Dataset` object but provided path is not a `Dataset`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1678\u001b[0m     )\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset_info_is_file:\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset_dict_is_file:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such files: '/home/quang_ai/AdvancedLLMReasoning/data_utils/data/subset_openmathinstruct_1/256K/dataset_info.json', nor '/home/quang_ai/AdvancedLLMReasoning/data_utils/data/subset_openmathinstruct_1/256K/state.json' found. Expected to load a `Dataset` object but provided path is not a `Dataset`."
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "subset_ds = Dataset.load_from_disk(\"data/subset_openmathinstruct_1/256K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7db0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = (\n",
    "    \"Solve the problem step by step. You can use Python code if needed.\\n\"\n",
    "    \"If you write code, use python markdown blocks (```python ... ```).\\n\"\n",
    "    \"Output ONLY the final number inside \\\\boxed{}. Example: \\\\boxed{42}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9ce8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 25 Dec 2025\n",
      "\n",
      "Solve the problem step by step. You can use Python code if needed.\n",
      "If you write code, use python markdown blocks (```python ... ```).\n",
      "Output ONLY the final number inside \\boxed{}. Example: \\boxed{42}.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Calculate 12 + 8.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "```python\n",
      "print(12+8)\n",
      "```\n",
      "The answer is \\boxed{20}.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "\n",
    "def format_llama3_prompt(example):\n",
    "    # 1. Tách phần Instruction (Luật) để làm System Prompt\n",
    "    system_msg = (\n",
    "        \"Solve the problem step by step. You can use Python code if needed.\\n\"\n",
    "        \"If you write code, use python markdown blocks (```python ... ```).\\n\"\n",
    "        \"Output ONLY the final number inside \\\\boxed{}. Example: \\\\boxed{42}.\"\n",
    "    )\n",
    "    \n",
    "    # 2. Tạo danh sách messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": example['question']},\n",
    "        {\"role\": \"assistant\", \"content\": example['solution']} # Đây là phần target để train\n",
    "    ]\n",
    "    \n",
    "    # 3. Áp dụng template\n",
    "    # tokenize=False để trả về chuỗi text, giúp bạn kiểm tra được định dạng trước khi token hóa\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Ví dụ test thử\n",
    "sample_data = {\n",
    "    \"question\": \"Calculate 12 + 8.\",\n",
    "    \"solution\": \"```python\\nprint(12+8)\\n```\\nThe answer is \\\\boxed{20}.\"\n",
    "}\n",
    "\n",
    "print(format_llama3_prompt(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129791df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
